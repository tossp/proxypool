package app

import (
	"fmt"
	"sync"
	"time"

	"github.com/One-Piecs/proxypool/pkg/geoIp"

	"github.com/One-Piecs/proxypool/config"
	"github.com/One-Piecs/proxypool/internal/cache"
	"github.com/One-Piecs/proxypool/internal/database"
	"github.com/One-Piecs/proxypool/log"
	"github.com/One-Piecs/proxypool/pkg/healthcheck"
	"github.com/One-Piecs/proxypool/pkg/provider"
	"github.com/One-Piecs/proxypool/pkg/proxy"
)

var location, _ = time.LoadLocation("PRC")

func CrawlGo() {
	wg := &sync.WaitGroup{}
	var pc = make(chan proxy.Proxy)
	for _, g := range Getters {
		wg.Add(1)
		go g.Get2ChanWG(pc, wg)
	}
	proxies := cache.GetProxies("allproxies")
	dbProxies := database.GetAllProxies()
	// Show last time result when launch
	if proxies == nil && dbProxies != nil {
		cache.SetProxies("proxies", dbProxies)
		cache.LastCrawlTime = "æŠ“å–ä¸­ï¼Œå·²è½½å…¥ä¸Šæ¬¡æ•°æ®åº“æ•°æ®"
		log.Infoln("Database loaded count: %d", len(dbProxies))
	}
	if dbProxies != nil {
		proxies = dbProxies.UniqAppendProxyList2(proxies)
	}
	if proxies == nil {
		proxies = make(proxy.ProxyList, 0)
	}

	go func() {
		wg.Wait()
		close(pc)
	}() // Note: ä¸ºä½•å¹¶å‘ï¼Ÿå¯ä»¥ä¸€è¾¹æŠ“å–ä¸€è¾¹è¯»å–è€ŒéæŠ“å®Œå†è¯»

	// æ¥æ”¶æ–°å¢ proxy, å»é‡
	mp := proxies.ToProxyMap()
	for p := range pc { // Note: pcå…³é—­åä¸èƒ½å‘é€æ•°æ®å¯ä»¥è¯»å–å‰©ä½™æ•°æ®
		if p != nil {
			mp.UniqAppendProxy(p)
		}
	}
	proxies = mp.ToProxyList()

	// proxies.NameClear()
	proxies = proxies.Derive()
	log.Infoln("CrawlGo unique proxy count: %d", len(proxies))

	// Clean Clash unsupported proxy because health check depends on clash
	proxies = provider.Clash{
		provider.Base{
			Proxies: &proxies,
		},
	}.CleanProxies()
	log.Infoln("CrawlGo clash supported proxy count: %d", len(proxies))

	cache.SetProxies("allproxies", proxies)
	cache.AllProxiesCount = proxies.Len()
	log.Infoln("AllProxiesCount: %d", cache.AllProxiesCount)
	cache.SSProxiesCount = proxies.TypeLen("ss")
	log.Infoln("SSProxiesCount: %d", cache.SSProxiesCount)
	cache.SSRProxiesCount = proxies.TypeLen("ssr")
	log.Infoln("SSRProxiesCount: %d", cache.SSRProxiesCount)
	cache.VmessProxiesCount = proxies.TypeLen("vmess")
	log.Infoln("VmessProxiesCount: %d", cache.VmessProxiesCount)
	cache.TrojanProxiesCount = proxies.TypeLen("trojan")
	log.Infoln("TrojanProxiesCount: %d", cache.TrojanProxiesCount)
	cache.LastCrawlTime = time.Now().In(location).Format("2006-01-02 15:04:05")

	// èŠ‚ç‚¹å¯ç”¨æ€§æ£€æµ‹ï¼Œä½¿ç”¨batchsizeä¸èƒ½é™ä½å†…å­˜å ç”¨ï¼Œåªæ˜¯ä¸ºäº†çœ‹æ€§èƒ½
	log.Infoln("Now proceed proxy health check...")
	/*
		b := 1000
		round := len(proxies) / b
		okproxies := make(proxy.ProxyList, 0)
		for i := 0; i < round; i++ {
			okproxies = append(okproxies, healthcheck.CleanBadProxiesWithWorkpool(proxies[i*b:(i+1)*b])...)
			log.Infoln("\tChecking round: %d", i)
		}
		okproxies = append(okproxies, healthcheck.CleanBadProxiesWithWorkpool(proxies[round*b:])...)
		proxies = okproxies
	*/
	proxies = healthcheck.CleanBadProxiesWithWorkpool(proxies)

	log.Infoln("CrawlGo clash usable proxy count: %d", len(proxies))

	// é‡å‘½åèŠ‚ç‚¹åç§°ä¸ºç±»ä¼¼US_01çš„æ ¼å¼ï¼Œå¹¶æŒ‰å›½å®¶æ’åº
	proxies.NameClear()
	proxies.NameAddCountry().Sort()
	log.Infoln("Proxy rename DONE!")
	/*
		// ä¸­è½¬æ£€æµ‹å¹¶å‘½å
		healthcheck.RelayCheck(proxies)
		for i, _ := range proxies {
			if s, ok := healthcheck.ProxyStats.Find(proxies[i]); ok {
				if s.Relay == true {
					_, c, e := geoIp.GeoIpDB.Find(s.OutIp)
					if e == nil {
						proxies[i].SetName(fmt.Sprintf("Relay_%s-%s", proxies[i].BaseInfo().Name, c))
					}
				} else if s.Pool == true {
					proxies[i].SetName(fmt.Sprintf("Pool_%s", proxies[i].BaseInfo().Name))
				}
			}
		}
	*/
	// ä¸­è½¬æ£€æµ‹å¹¶å‘½å
	healthcheck.RelayCheckWorkpool(proxies)
	for i, _ := range proxies {
		if s, ok := healthcheck.ProxyStats.Find(proxies[i]); ok {
			if s.Relay == true {
				_, c, e := geoIp.GeoIpDB.Find(s.OutIp)
				if e == nil {
					// proxies[i].SetName(fmt.Sprintf("Relay_%s-%s", proxies[i].BaseInfo().Name, c))

					if proxies[i].BaseInfo().Name == "ğŸ‡¨ğŸ‡³ CN" {
						// proxies[i].SetCountry(fmt.Sprintf("%s-%s", proxies[i].BaseInfo().Name, c))
						// proxies[i].SetName(fmt.Sprintf("Relay_%s-%s", proxies[i].BaseInfo().Name, c))

						proxies[i].SetCountry(fmt.Sprintf("%s", c))
						proxies[i].SetName(fmt.Sprintf("Relay %s", proxies[i].BaseInfo().Name, c))
					} else {
						proxies[i].SetCountry(c)
						proxies[i].SetName(c)
					}

				}
			} else if s.Pool == true {
				// proxies[i].SetName(fmt.Sprintf("Pool_%s", proxies[i].BaseInfo().Name))
			}
		}
	}

	proxies.Sort().NameAddIndex()

	// å¯ç”¨èŠ‚ç‚¹å­˜å‚¨
	cache.SetProxies("proxies", proxies)
	cache.UsefullProxiesCount = proxies.Len()
	database.SaveProxyList(proxies)
	database.ClearOldItems()

	log.Infoln("Usablility checking done. Open %s to check", config.Config.Domain+":"+config.Config.Port)

	// æµ‹é€Ÿ
	speedTestNew(proxies)
	cache.SetString("clashproxies", provider.Clash{
		provider.Base{
			Proxies: &proxies,
		},
	}.Provide()) // update static string provider
	cache.SetString("surgeproxies", provider.Surge{
		provider.Base{
			Proxies: &proxies,
		},
	}.Provide())
	cache.SetString("loonproxies", provider.Loon{
		provider.Base{
			Proxies: &proxies,
		},
	}.Provide())
}

// Speed test for new proxies
func speedTestNew(proxies proxy.ProxyList) {
	if config.Config.SpeedTest {
		cache.IsSpeedTest = "å·²å¼€å¯"
		if config.Config.Timeout > 0 {
			healthcheck.SpeedTimeout = time.Second * time.Duration(config.Config.Timeout)
		}
		healthcheck.SpeedTestNewWithWorkpool(proxies, config.Config.Connection)
	} else {
		cache.IsSpeedTest = "æœªå¼€å¯"
	}
}

// Speed test for all proxies in proxy.ProxyList
func SpeedTest(proxies proxy.ProxyList) {
	if config.Config.SpeedTest {
		cache.IsSpeedTest = "å·²å¼€å¯"
		if config.Config.Timeout > 0 {
			healthcheck.SpeedTimeout = time.Second * time.Duration(config.Config.Timeout)
		}
		healthcheck.SpeedTestAllWithWorkpool(proxies, config.Config.Connection)
	} else {
		cache.IsSpeedTest = "æœªå¼€å¯"
	}
}
